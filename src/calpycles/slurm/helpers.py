"""Functionalities to run pycles samples or ensembles.

The setup herein refers to Euler at ETH using slurm.
The computations will be performed in the current environment.
"""

# Standard library
import os
import shutil
from typing import Any
from typing import Dict
from typing import List
from typing import Tuple

# First-party
from calpycles.helpers import ensure_path
from calpycles.slurm.run_job_in_array import run_job_in_array_script

# flake8: noqa: E501
# ignore E501 line too long


def run_array(
    path: str,  # path of the ensemble
    job_settings: Dict[str, Any],
    verbose: bool = False,
) -> None:
    """Submit an ensemble as a job array.

    Job settings must include:
        job_settings = {
            "J": str,
            "n": int,
            "mem-per-cpu": str, # "1G",
            "time": int, # 60,
            "n_samples": int,
        }
    Call dump_slurm_info() first to create the required files.
    """
    cmds_path = os.path.join(path, "slurm", "commands")
    paths_path = os.path.join(path, "slurm", "paths")

    assert os.path.exists(
        cmds_path
    ), f"File {cmds_path} does not exist. Call dump_slurm_info() first."
    assert os.path.exists(
        paths_path
    ), f"File {paths_path} does not exist. Call dump_slurm_info() first."

    job_settings.update(
        {
            "output": "slurm_ensemble_%A_%a.out",
            "error": "slurm_ensemble_%A_%a.err",
        }
    )

    slurm_script = f"""#!/bin/bash

### THIS FILE IS GENERATED BY calpycles.slurm.helpers, EDIT IN THERE!!!

### JOB SETTINGS
#SBATCH -n {job_settings['n']}
#SBATCH --array=[0-{job_settings['n_samples'] - 1}]
#SBATCH --time={job_settings['time']}
#SBATCH --mem-per-cpu={job_settings['mem-per-cpu']}
#SBATCH -A ls_math
#SBATCH --job-name={job_settings['J']}
#SBATCH --output={job_settings['output']}
#SBATCH --error={job_settings['error']}
#SBATCH --constraint="ibfabric6|ibfabric7"

## * Openmpi/4.1.6: WARNING: This openmpi is known to have an issue with Euler 9

### SETUP THE ENVIRONMENT
echo Python used within the sample job:
which python

### DO THE COMPUTATION
python {run_job_in_array_script} --cmds_path {cmds_path} --paths_path {paths_path} --index $SLURM_ARRAY_TASK_ID
"""

    if verbose:
        print(
            "Submitting ensemble from slurm script stored in ",
            os.path.join(path, "slurm_script.sh"),
        )

    cwd = os.getcwd()
    os.chdir(path)

    # write script to file
    os.system(f"echo '{slurm_script}' > slurm_script.sh")

    # run command
    os.system("sbatch slurm_script.sh")

    os.chdir(cwd)


def run_single(
    path: str,  # path of the sample, e.g. ensemble/mean/
    cmd: str,
    job_settings: Dict[str, Any],
    verbose: bool = False,
) -> None:
    """Submit a single sample as a job array.

    Job settings must include:
        job_settings = {
            "J": str, # job name
            "n": int, # number of cores
            "mem-per-cpu": str, # "1G",
            "time": int, # 60, # s
        }
    """
    job_settings.update(
        {
            "output": "slurm_single_%A.out",
            "error": "slurm_sinlge_%A.err",
        }
    )

    slurm_script = f"""#!/bin/bash

### THIS FILE IS GENERATED BY calpycles.slurm.helpers, EDIT IN THERE!!!

### JOB SETTINGS
#SBATCH -n {job_settings['n']}
#SBATCH --time={job_settings['time']}
#SBATCH --mem-per-cpu={job_settings['mem-per-cpu']}
#SBATCH -A ls_math
#SBATCH --job-name={job_settings['J']}
#SBATCH --output={job_settings['output']}
#SBATCH --error={job_settings['error']}
#SBATCH --constraint="ibfabric6|ibfabric7"

## * Openmpi/4.1.6: WARNING: This openmpi is known to have an issue with Euler 9

### SETUP THE ENVIRONMENT
echo Python used within the sample job:
which python

### DO THE COMPUTATION
{cmd}
    """

    if verbose:
        print(
            "Submitting single sample from slurm script stored in ",
            os.path.join(path, "slurm_script.sh"),
        )

    cwd = os.getcwd()
    os.chdir(path)

    # write script to file
    os.system(f"echo '{slurm_script}' > slurm_script.sh")

    # run command
    os.system("sbatch slurm_script.sh")

    os.chdir(cwd)


def move_slurm_files(
    path: str,
) -> None:
    """Clean up after calling run_array() or run_single().

    Moving the following files to path/slurm/:
        - slurm_ensemble_ID_id.out
        - slurm_ensemble_ID_id.err
        - slurm_script.sh
    """
    slurm_path = os.path.join(path, "slurm")
    ensure_path(slurm_path)

    files = os.listdir(path)
    for f in files:
        if f.startswith("slurm_"):
            source = os.path.join(path, f)
            target = os.path.join(slurm_path, f)
            shutil.move(source, target)


def dump_slurm_info(
    cmds: List[str],
    paths: List[str],
    path: str,
) -> None:
    """Dump information required by each single job in the array."""
    slurm_path = os.path.join(path, "slurm")
    ensure_path(slurm_path)

    cmds_path = os.path.join(slurm_path, "commands")
    ensure_path(cmds_path)
    for i, cmd in enumerate(cmds):
        with open(os.path.join(cmds_path, str(i) + ".txt"), "w", encoding="utf-8") as f:
            f.write(cmd)

    paths_path = os.path.join(slurm_path, "paths")
    ensure_path(paths_path)
    for i, p in enumerate(paths):
        with open(
            os.path.join(paths_path, str(i) + ".txt"), "w", encoding="utf-8"
        ) as f:
            f.write(p)


def make_job_settings(
    name: str,
    nproc: int,
    mem_in_m: float,
    time_in_h: float,
    n_samples: int = 1,
    test: bool = False,
) -> Tuple[Dict[str, Any], float]:
    """Create job settings for slurm and determine max duration."""
    if test:
        mem_in_m = 1000
        t = "00:10:00"
        max_time_s = 10 * 60.0
    else:
        # convert computing time in hours to string
        t = str(time_in_h)
        if len(t) == 1:
            t = "0" + t
        t = t + ":00:00"
        max_time_s = time_in_h * 3600.0
    mem_per_cpu_in_m = int(mem_in_m / nproc)
    mem_per_cpu_in_m = max(mem_per_cpu_in_m, 500)
    mem_per_cpu = str(mem_per_cpu_in_m) + "M"
    job_settings = {
        "J": name,
        "n": nproc,
        "mem-per-cpu": mem_per_cpu,
        "time": t,
        "n_samples": n_samples,
    }
    return job_settings, max_time_s
